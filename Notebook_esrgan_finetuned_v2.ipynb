{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":97753,"databundleVersionId":11639668,"sourceType":"competition"},{"sourceId":11301515,"sourceType":"datasetVersion","datasetId":7067698}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:46:29.274723Z","iopub.execute_input":"2025-07-04T06:46:29.274938Z","iopub.status.idle":"2025-07-04T06:46:30.200731Z","shell.execute_reply.started":"2025-07-04T06:46:29.274917Z","shell.execute_reply":"2025-07-04T06:46:30.199979Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"pip install git+https://github.com/XPixelGroup/BasicSR.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:46:30.202223Z","iopub.execute_input":"2025-07-04T06:46:30.202576Z","iopub.status.idle":"2025-07-04T06:46:41.043086Z","shell.execute_reply.started":"2025-07-04T06:46:30.202554Z","shell.execute_reply":"2025-07-04T06:46:41.042178Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/XPixelGroup/BasicSR.git\n  Cloning https://github.com/XPixelGroup/BasicSR.git to /tmp/pip-req-build-wc1b10wr\n  Running command git clone --filter=blob:none --quiet https://github.com/XPixelGroup/BasicSR.git /tmp/pip-req-build-wc1b10wr\n  Resolved https://github.com/XPixelGroup/BasicSR.git to commit 8d56e3a045f9fb3e1d8872f92ee4a4f07f886b0a\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting addict (from basicsr==1.4.2)\n  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\nRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from basicsr==1.4.2) (1.0.0)\nCollecting lmdb (from basicsr==1.4.2)\n  Downloading lmdb-1.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from basicsr==1.4.2) (1.26.4)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from basicsr==1.4.2) (4.10.0.84)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from basicsr==1.4.2) (11.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from basicsr==1.4.2) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from basicsr==1.4.2) (2.32.3)\nRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from basicsr==1.4.2) (0.25.0)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from basicsr==1.4.2) (1.13.1)\nCollecting tb-nightly (from basicsr==1.4.2)\n  Downloading tb_nightly-2.20.0a20250703-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from basicsr==1.4.2) (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from basicsr==1.4.2) (0.20.1+cu121)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from basicsr==1.4.2) (4.67.1)\nCollecting yapf (from basicsr==1.4.2)\n  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->basicsr==1.4.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->basicsr==1.4.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->basicsr==1.4.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->basicsr==1.4.2) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->basicsr==1.4.2) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->basicsr==1.4.2) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr==1.4.2) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr==1.4.2) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr==1.4.2) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr==1.4.2) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr==1.4.2) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr==1.4.2) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.7->basicsr==1.4.2) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr==1.4.2) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr==1.4.2) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr==1.4.2) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr==1.4.2) (2025.1.31)\nRequirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr==1.4.2) (2.36.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr==1.4.2) (2024.12.12)\nRequirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr==1.4.2) (24.2)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr==1.4.2) (0.4)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr==1.4.2) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr==1.4.2) (1.68.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr==1.4.2) (3.7)\nRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr==1.4.2) (3.20.3)\nRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr==1.4.2) (75.1.0)\nRequirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr==1.4.2) (1.17.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr==1.4.2) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr==1.4.2) (3.1.3)\nRequirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr==1.4.2) (4.3.6)\nRequirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr==1.4.2) (2.2.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tb-nightly->basicsr==1.4.2) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->basicsr==1.4.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->basicsr==1.4.2) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->basicsr==1.4.2) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->basicsr==1.4.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->basicsr==1.4.2) (2024.2.0)\nDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\nDownloading lmdb-1.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (294 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading tb_nightly-2.20.0a20250703-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading yapf-0.43.0-py3-none-any.whl (256 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: basicsr\n  Building wheel for basicsr (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for basicsr: filename=basicsr-1.4.2-py3-none-any.whl size=536099 sha256=96b1d6247389ed95c86d28582e166f51c8a0f9f96c59649b0c1c79ad8e9a4e32\n  Stored in directory: /tmp/pip-ephem-wheel-cache-mos3tinx/wheels/77/d7/a0/c82982051cfef787300bafbeb5716ab057f63aa51b84f768ba\nSuccessfully built basicsr\nInstalling collected packages: lmdb, addict, yapf, tb-nightly, basicsr\nSuccessfully installed addict-2.4.0 basicsr-1.4.2 lmdb-1.6.2 tb-nightly-2.20.0a20250703 yapf-0.43.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from basicsr.archs.rrdbnet_arch import RRDBNet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:46:41.044551Z","iopub.execute_input":"2025-07-04T06:46:41.044818Z","iopub.status.idle":"2025-07-04T06:46:47.876133Z","shell.execute_reply.started":"2025-07-04T06:46:41.044795Z","shell.execute_reply":"2025-07-04T06:46:47.875454Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"pip install einops timm opencv-python pytorch-lightning","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:46:47.876873Z","iopub.execute_input":"2025-07-04T06:46:47.877291Z","iopub.status.idle":"2025-07-04T06:46:51.454699Z","shell.execute_reply.started":"2025-07-04T06:46:47.877267Z","shell.execute_reply":"2025-07-04T06:46:51.453759Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\nRequirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (1.0.12)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\nRequirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (2.5.0.post0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.1+cu121)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.29.0)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\nRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\nRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.67.1)\nRequirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.12.0)\nRequirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.6.1)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (24.2)\nRequirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.12.2)\nRequirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.12.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.12)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.17.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (11.0.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.18.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.2->opencv-python) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2025.1.31)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Importing Required Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport torch\nimport numpy as np\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision.transforms import ToTensor\nfrom torch import nn, optim\nfrom skimage.metrics import peak_signal_noise_ratio as psnr\nfrom basicsr.archs.rrdbnet_arch import RRDBNet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:46:51.455808Z","iopub.execute_input":"2025-07-04T06:46:51.456134Z","iopub.status.idle":"2025-07-04T06:46:51.504143Z","shell.execute_reply.started":"2025-07-04T06:46:51.456109Z","shell.execute_reply":"2025-07-04T06:46:51.503270Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:46:51.507198Z","iopub.execute_input":"2025-07-04T06:46:51.507453Z","iopub.status.idle":"2025-07-04T06:46:51.567728Z","shell.execute_reply.started":"2025-07-04T06:46:51.507429Z","shell.execute_reply":"2025-07-04T06:46:51.566826Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Define Custom Dataset for Paired Image Super-Resolution","metadata":{}},{"cell_type":"code","source":"class PairedImageDataset(Dataset):\n    def __init__(self, low_dir, high_dir):\n        self.low_dir = low_dir\n        self.high_dir = high_dir\n        self.filenames = sorted(os.listdir(low_dir))\n\n    def __len__(self):\n        return len(self.filenames)\n\n    def __getitem__(self, idx):\n        filename = self.filenames[idx]\n        low = cv2.imread(os.path.join(self.low_dir, filename))[:, :, ::-1]\n        high = cv2.imread(os.path.join(self.high_dir, filename))[:, :, ::-1]\n        low = (low / 255.0).astype(np.float32)\n        high = (high / 255.0).astype(np.float32)\n        return ToTensor()(low), ToTensor()(high)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:46:51.569317Z","iopub.execute_input":"2025-07-04T06:46:51.569577Z","iopub.status.idle":"2025-07-04T06:46:51.589627Z","shell.execute_reply.started":"2025-07-04T06:46:51.569555Z","shell.execute_reply":"2025-07-04T06:46:51.588789Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom torchvision.transforms import ToTensor\nimport cv2\n\n\nclass PairedImageDataset(Dataset):\n    def __init__(self, low_dir, high_dir):\n        self.low_dir = low_dir\n        self.high_dir = high_dir\n        self.filenames = sorted(os.listdir(low_dir))\n\n    def __len__(self):\n        return len(self.filenames)\n\n    def __getitem__(self, idx):\n        filename = self.filenames[idx]\n\n        low_path = os.path.join(self.low_dir, filename)\n        high_path = os.path.join(self.high_dir, filename)\n\n        # Load with cv2 and ensure it loaded correctly\n        low = cv2.imread(low_path)\n        high = cv2.imread(high_path)\n\n        if low is None or high is None:\n            raise FileNotFoundError(f\"Missing file: {filename}\")\n\n        # Convert BGR to RGB\n        low = cv2.cvtColor(low, cv2.COLOR_BGR2RGB)\n        high = cv2.cvtColor(high, cv2.COLOR_BGR2RGB)\n\n        # Normalize to [0, 1]\n        low = (low / 255.0).astype(np.float32)\n        high = (high / 255.0).astype(np.float32)\n\n        # Convert to torch.Tensor\n        return ToTensor()(low), ToTensor()(high)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:46:51.590447Z","iopub.execute_input":"2025-07-04T06:46:51.590713Z","iopub.status.idle":"2025-07-04T06:46:51.608397Z","shell.execute_reply.started":"2025-07-04T06:46:51.590691Z","shell.execute_reply":"2025-07-04T06:46:51.607522Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import torchvision.transforms as T\nfrom torchvision.transforms import ToTensor, ToPILImage\n\n# Define your transform pipeline\ntransform = T.Compose([\n    T.ToPILImage(),\n    T.RandomHorizontalFlip(),\n    T.RandomVerticalFlip(),\n    T.RandomRotation(10),\n    T.ToTensor()\n])\n\nclass PairedImageDataset(Dataset):\n    def __init__(self, low_dir, high_dir, transform=None):\n        self.low_dir = low_dir\n        self.high_dir = high_dir\n        self.filenames = sorted(os.listdir(low_dir))\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.filenames)\n\n    def __getitem__(self, idx):\n        filename = self.filenames[idx]\n        \n        # Load and normalize\n        low = cv2.imread(os.path.join(self.low_dir, filename))[:, :, ::-1]\n        high = cv2.imread(os.path.join(self.high_dir, filename))[:, :, ::-1]\n\n        low = (low * 255.0).clip(0, 255).astype(np.uint8)  # Back to uint8 for PIL\n        high = (high * 255.0).clip(0, 255).astype(np.uint8)\n\n        if self.transform:\n            # Ensure both images undergo the same random transformation\n            seed = np.random.randint(99999)\n            torch.manual_seed(seed)\n            low = self.transform(low)\n            torch.manual_seed(seed)\n            high = self.transform(high)\n        else:\n            low = ToTensor()(low.astype(np.float32) / 255.0)\n            high = ToTensor()(high.astype(np.float32) / 255.0)\n\n        return low, high\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:46:51.609347Z","iopub.execute_input":"2025-07-04T06:46:51.609662Z","iopub.status.idle":"2025-07-04T06:46:51.627507Z","shell.execute_reply.started":"2025-07-04T06:46:51.609633Z","shell.execute_reply":"2025-07-04T06:46:51.626664Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### Loading Pretrained Real-ESRGAN Model","metadata":{}},{"cell_type":"code","source":"def load_esrgan_model():\n    model_path = '/kaggle/input/real-esrgan-model/RealESRGAN_x4plus.pth'\n    model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32)\n    state_dict = torch.load(model_path, map_location='cpu')\n    if 'params_ema' in state_dict:\n        state_dict = state_dict['params_ema']\n    model.load_state_dict(state_dict, strict=True)\n    torch.cuda.empty_cache()\n    model.to(device).eval()\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:46:51.628364Z","iopub.execute_input":"2025-07-04T06:46:51.628585Z","iopub.status.idle":"2025-07-04T06:46:51.647885Z","shell.execute_reply.started":"2025-07-04T06:46:51.628565Z","shell.execute_reply":"2025-07-04T06:46:51.646760Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"###  Preprocessing and Inference Image Conversion","metadata":{}},{"cell_type":"code","source":"# Function to upscale a single image using the model\n\ndef process(model, img):\n    # Normalize image to [0, 1]\n    img = (img / 255.0).astype(np.float32)\n\n    # Convert image to tensor and add batch dimension\n    img_tensor = ToTensor()(img).unsqueeze(0).to(device)\n\n    # Forward pass through the model\n    with torch.no_grad():\n        sr = model(img_tensor).clamp(0, 1)\n\n    # Convert model output to numpy array and denormalize to [0, 255]\n    sr_img = sr.squeeze().permute(1, 2, 0).cpu().numpy()\n    return (sr_img * 255.0).round().astype(np.uint8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:46:51.648702Z","iopub.execute_input":"2025-07-04T06:46:51.648925Z","iopub.status.idle":"2025-07-04T06:46:51.663691Z","shell.execute_reply.started":"2025-07-04T06:46:51.648905Z","shell.execute_reply":"2025-07-04T06:46:51.662787Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"### Evaluation Function","metadata":{}},{"cell_type":"code","source":"# Evaluate model using PSNR on validation set\ndef evaluate(model, val_low_dir, val_high_dir):\n    scores = []\n    model.eval()\n    for filename in os.listdir(val_low_dir):\n        low = cv2.imread(os.path.join(val_low_dir, filename))[:, :, ::-1]\n        high = cv2.imread(os.path.join(val_high_dir, filename))[:, :, ::-1]\n        output = process(model, low)\n        scores.append(psnr(high, output))\n\n    # Return average PSNR score\n    return np.mean(scores)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:46:51.664559Z","iopub.execute_input":"2025-07-04T06:46:51.664814Z","iopub.status.idle":"2025-07-04T06:46:51.683179Z","shell.execute_reply.started":"2025-07-04T06:46:51.664792Z","shell.execute_reply":"2025-07-04T06:46:51.682369Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Inference on Test Images","metadata":{}},{"cell_type":"code","source":"# Inference function for test images\ndef infer(model, test_dir, save_dir):\n    # Ensure output directory exists\n    os.makedirs(save_dir, exist_ok=True)\n\n    # Set the model to evaluation mode \n    model.eval()\n\n    \n    for filename in os.listdir(test_dir):\n        img = cv2.imread(os.path.join(test_dir, filename))[:, :, ::-1]\n        sr_img = process(model, img)\n        cv2.imwrite(os.path.join(save_dir, filename), sr_img[:, :, ::-1])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:46:51.683959Z","iopub.execute_input":"2025-07-04T06:46:51.684241Z","iopub.status.idle":"2025-07-04T06:46:51.702409Z","shell.execute_reply.started":"2025-07-04T06:46:51.684209Z","shell.execute_reply":"2025-07-04T06:46:51.701664Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Training Function (Fine-Tuning)","metadata":{}},{"cell_type":"code","source":"def train(model, train_loader, epochs=10, lr=1e-4):\n\n    # Set model to training mode\n    model.train()\n\n    # defining mean square error as the loss function\n    criterion = nn.MSELoss()\n\n    # use of adam optimizer\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n\n    # train for the specified num of epochs\n    for epoch in range(epochs):\n\n        # progress bar for tracking status\n        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n\n        # Iterate through each batch\n        for lr_img, hr_img in pbar:\n            \n            lr_img, hr_img = lr_img.to(device), hr_img.to(device)\n\n            # clear gradiaent before bp\n            optimizer.zero_grad()\n\n            # forword pass\n            sr = model(lr_img)\n            loss = criterion(sr, hr_img)\n            loss.backward()\n\n            # update model parameters\n            optimizer.step()\n\n            # show current batch\n            pbar.set_postfix(loss=loss.item())\n\n        # clear cache memory to avoid mem. overflow\n        torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:46:51.703262Z","iopub.execute_input":"2025-07-04T06:46:51.703526Z","iopub.status.idle":"2025-07-04T06:46:51.719734Z","shell.execute_reply.started":"2025-07-04T06:46:51.703505Z","shell.execute_reply":"2025-07-04T06:46:51.718897Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(3, 64, 3, stride=2, padding=1),     # 🔁 Changed from 1 to 3\n            nn.LeakyReLU(0.2, inplace=True),\n\n            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n\n            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.2, inplace=True),\n\n            nn.Conv2d(256, 512, 3, stride=2, padding=1),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.2, inplace=True),\n\n            nn.AdaptiveAvgPool2d((1, 1)),\n            nn.Flatten(),\n            nn.Linear(512, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return self.model(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:46:51.720638Z","iopub.execute_input":"2025-07-04T06:46:51.720937Z","iopub.status.idle":"2025-07-04T06:46:51.742130Z","shell.execute_reply.started":"2025-07-04T06:46:51.720909Z","shell.execute_reply":"2025-07-04T06:46:51.741278Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\nimport gc\nfrom tqdm import tqdm\n\ndef train_with_gan(model, discriminator, train_loader, epochs=2, lr=1e-4, gan_weight=1e-3):\n    model.train()\n    discriminator.train()\n\n    # Loss functions\n    mse_loss = nn.MSELoss()\n    gan_loss = nn.BCEWithLogitsLoss()\n\n    # Optimizers\n    optimizer_G = optim.Adam(model.parameters(), lr=lr)\n    optimizer_D = optim.Adam(discriminator.parameters(), lr=lr)\n\n    for epoch in range(epochs):\n        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n        for lr_img, hr_img in pbar:\n            lr_img, hr_img = lr_img.to(device), hr_img.to(device)\n\n            valid = torch.ones((lr_img.size(0), 1), device=device)\n            fake = torch.zeros((lr_img.size(0), 1), device=device)\n\n            # ---- Train Generator ----\n            optimizer_G.zero_grad()\n            sr = model(lr_img)\n            pred_fake = discriminator(sr)\n\n            loss_mse = mse_loss(sr, hr_img)\n            loss_gan = gan_loss(pred_fake, valid)\n            loss_G = loss_mse + gan_weight * loss_gan\n            loss_G.backward()\n            optimizer_G.step()\n\n            # ---- Train Discriminator ----\n            optimizer_D.zero_grad()\n            pred_real = discriminator(hr_img.detach())\n            pred_fake = discriminator(sr.detach())\n            loss_real = gan_loss(pred_real, valid)\n            loss_fake = gan_loss(pred_fake, fake)\n            loss_D = 0.5 * (loss_real + loss_fake)\n            loss_D.backward()\n            optimizer_D.step()\n\n            pbar.set_postfix(MSE=loss_mse.item(), GAN=loss_gan.item())\n\n            # Free memory\n            del sr, pred_fake, pred_real, loss_G, loss_D, loss_mse, loss_gan\n            torch.cuda.empty_cache()\n            gc.collect()\n\n        torch.cuda.empty_cache()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:46:51.743100Z","iopub.execute_input":"2025-07-04T06:46:51.743387Z","iopub.status.idle":"2025-07-04T06:46:51.761725Z","shell.execute_reply.started":"2025-07-04T06:46:51.743363Z","shell.execute_reply":"2025-07-04T06:46:51.760852Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## Main Execution Block","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Load model\n    model = load_esrgan_model()\n    # discriminator = Discriminator().to(device)\n\n\n    # Prepare Dataset\n    train_dataset = PairedImageDataset(\n        '/kaggle/input/dlp-jan-2025-nppe-3/archive/train/train',\n        '/kaggle/input/dlp-jan-2025-nppe-3/archive/train/gt'\n        # transform=transform\n    )\n\n    # Use only half data for training\n    # half_size = len(train_dataset) // 2\n    # train_subset, _ = random_split(train_dataset, [half_size, len(train_dataset) - half_size])\n    # train_loader = DataLoader(train_subset, batch_size=1, shuffle=True)\n\n    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n\n    # Fine-tune the model\n    print(\"Starting fine-tuning...\")\n    train(model, train_loader, epochs=2, lr=1e-4)\n    torch.save(model.state_dict(), 'esrgan_finetuned.pth')\n    print(\"Model weights saved as esrgan_finetuned.pth\")\n    # train_with_gan(model, train_loader, epochs=1, lr=1e-3)\n    # train_with_gan(model, discriminator, train_loader, epochs=2, lr=1e-4)\n\n    # # Evaluate after fine-tuning\n    # print(\"Evaluating on validation set...\")\n    # val_psnr = evaluate(model,\n    #     '/kaggle/input/dlp-jan-2025-nppe-3/archive/val/val',\n    #     '/kaggle/input/dlp-jan-2025-nppe-3/archive/val/gt'\n    # )\n    # print(f\"Validation PSNR: {val_psnr:.2f}\")\n\n    # Inference on test set\n    print(\"Running inference on test set...\")\n    infer(model, '/kaggle/input/dlp-jan-2025-nppe-3/archive/test', '/kaggle/working/esrgan_outputs')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:46:51.762687Z","iopub.execute_input":"2025-07-04T06:46:51.762907Z","iopub.status.idle":"2025-07-04T07:12:08.343980Z","shell.execute_reply.started":"2025-07-04T06:46:51.762889Z","shell.execute_reply":"2025-07-04T07:12:08.343264Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-10-22ee74947d21>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state_dict = torch.load(model_path, map_location='cpu')\n","output_type":"stream"},{"name":"stdout","text":"Starting fine-tuning...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2: 100%|██████████| 1105/1105 [12:38<00:00,  1.46it/s, loss=1.12e-8]\nEpoch 2/2: 100%|██████████| 1105/1105 [12:21<00:00,  1.49it/s, loss=1.88e-8]\n","output_type":"stream"},{"name":"stdout","text":"Model weights saved as esrgan_finetuned.pth\nRunning inference on test set...\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"# infer(model, '/kaggle/input/dlp-jan-2025-nppe-3/archive/test', '/kaggle/working/esrgan_outputs')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T07:12:08.346514Z","iopub.execute_input":"2025-07-04T07:12:08.346775Z","iopub.status.idle":"2025-07-04T07:12:08.350168Z","shell.execute_reply.started":"2025-07-04T07:12:08.346753Z","shell.execute_reply":"2025-07-04T07:12:08.349344Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# from PIL import Image\n\n# def images_to_csv(folder_path, output_csv):\n#     data_rows = []\n#     for filename in os.listdir(folder_path):\n#         if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n#             image_path = os.path.join(folder_path, filename)\n#             image = Image.open(image_path).convert('L') \n#             image_array = np.array(image).flatten()[::8]\n#             # Replace 'test_' with 'gt_' in the ID\n#             image_id = filename.split('.')[0].replace('test_', 'gt_')\n#             data_rows.append([image_id, *image_array])\n#     column_names = ['ID'] + [f'pixel_{i}' for i in range(len(data_rows[0]) - 1)]\n#     df = pd.DataFrame(data_rows, columns=column_names)\n#     df.to_csv(output_csv, index=False)\n#     print(f'Successfully saved to {output_csv}')\n\n# folder_path = '/kaggle/working/esrgan_outputs'\n# output_csv = 'submission.csv'\n# images_to_csv(folder_path, output_csv)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T07:12:08.351038Z","iopub.execute_input":"2025-07-04T07:12:08.351273Z","iopub.status.idle":"2025-07-04T07:12:08.369445Z","shell.execute_reply.started":"2025-07-04T07:12:08.351254Z","shell.execute_reply":"2025-07-04T07:12:08.368733Z"}},"outputs":[],"execution_count":19}]}